{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from random import choice\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import etree\n",
    "from time import sleep\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df = pd.read_csv('./data/nasdaq_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    url = \"https://free-proxy-list.net/\"\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    dom = etree.HTML(str(soup))\n",
    "\n",
    "    tr_list = dom.xpath('//*[@id=\"proxylisttable\"]/tbody/tr')\n",
    "    proxy_server_list = []\n",
    "\n",
    "    for tr in tr_list:\n",
    "        ip = tr.xpath(\"td[1]/text()\").extract_first()\n",
    "        port = tr.xpath(\"td[2]/text()\").extract_first()\n",
    "        https = tr.xpath(\"td[7]/text()\").extract_first()\n",
    "\n",
    "        if https == \"yes\":\n",
    "            server = f\"{ip}:{port}\"\n",
    "            proxy_server_list.append(server)\n",
    "\n",
    "    return proxy_server_list\n",
    "\n",
    "\n",
    "PROXY_SERVER_LIST = get_proxies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_marketwatch(symbol: str):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    proxy_server = choice(PROXY_SERVER_LIST)\n",
    "    proxies = {\"http\": proxy_server, \"https\": proxy_server}\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(\n",
    "            f\"https://www.marketwatch.com/investing/stock/{symbol.lower()}/financials/income\",\n",
    "            headers=headers,\n",
    "            proxies=proxies,\n",
    "            timeout=5,\n",
    "        )\n",
    "        soup = BeautifulSoup(resp.text)\n",
    "    except:\n",
    "        print(symbol, \"request failed.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        financial_table = soup.find(\n",
    "            \"table\", attrs={\"class\": \"table table--overflow align--right\"}\n",
    "        )\n",
    "        df = pd.read_html(str(financial_table))[0]\n",
    "        df = df.drop(df.columns[[-1]], axis=1)  # drop 5-year trend column\n",
    "    except:\n",
    "        print(symbol, \"parsing failed.\")\n",
    "        return None\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_scrape(start: int, end: int):\n",
    "    result = pd.DataFrame()\n",
    "    for i in tqdm(range(start, end)):\n",
    "        name = nasdaq_df.loc[i, 'Name']\n",
    "        symbol = nasdaq_df.loc[i, 'Symbol']\n",
    "        industry = nasdaq_df.loc[i, 'Industry']\n",
    "        \n",
    "        df = scrape_marketwatch(symbol)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        # add multiindex level\n",
    "        df = pd.concat([df], keys=[industry], names=['Industry'])\n",
    "        df = pd.concat([df], keys=[symbol], names=['Symbol'])\n",
    "        df = pd.concat([df], keys=[name], names=['Name'])\n",
    "        \n",
    "        result = pd.concat([result, df])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nasdaq_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/CUop/Workspace/cuop/market_scrape/nasdaq_marketwatch.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/CUop/Workspace/cuop/market_scrape/nasdaq_marketwatch.ipynb#ch0000004?line=0'>1</a>\u001b[0m work_list \u001b[39m=\u001b[39m [(i, \u001b[39mmin\u001b[39m(i \u001b[39m+\u001b[39m \u001b[39m500\u001b[39m, \u001b[39mlen\u001b[39m(nasdaq_df))) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(nasdaq_df), \u001b[39m500\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/CUop/Workspace/cuop/market_scrape/nasdaq_marketwatch.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(work_list)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/CUop/Workspace/cuop/market_scrape/nasdaq_marketwatch.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m) \u001b[39mas\u001b[39;00m executor:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nasdaq_df' is not defined"
     ]
    }
   ],
   "source": [
    "work_list = [(i, min(i + 500, len(nasdaq_df))) for i in range(0, len(nasdaq_df), 500)]\n",
    "print(work_list)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = [executor.submit(thread_scrape, work[0], work[1]) for work in work_list]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        print(result)\n",
    "        df = pd.concat([df, result])\n",
    "\n",
    "df.to_csv('./data/nasdaq_full2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _conv_to_float(s):\n",
    "    if s == '-':\n",
    "        return None\n",
    "\n",
    "    if s[-1] == '%':\n",
    "        s = s.replace('%', '')\n",
    "    if s[-1] in list('BMK'):\n",
    "        powers = {'B': 10 ** 9, 'M': 10 ** 6, 'K': 10 ** 3, '': 1}\n",
    "        m = re.search(\"([0-9\\.]+)(M|B|K|)\", s)\n",
    "        if m:\n",
    "            val, mag = m.group(1), m.group(2)\n",
    "            return float(val) * powers[mag]\n",
    "    try:\n",
    "        result = float(s)\n",
    "    except:\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/nasdaq_marketcap_full.csv')\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "\n",
    "conv_list =['MarketCap', 'Income', 'Sales', 'GrossMargin', 'OperatingMargin', 'ProfitMargin']\n",
    "for col in conv_list:\n",
    "    df[col] = df[col].apply(_conv_to_float)\n",
    "\n",
    "nasdaq_df_proc = df.dropna(subset=['MarketCap'])\n",
    "\n",
    "nasdaq_df_proc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f2c90995bf61f046707788a0b73ac4bd8c7fa3f699490437d16f94fef7b744e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
